<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Create a Homelab from Scratch using latest best practices, patterns and tools."><meta name=author content="Javier Santos"><link href=https://jsa4000.github.io/homelab-ops/tools/microceph/ rel=canonical><link href=../manifest/ rel=prev><link href=../qemu/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.5.3, mkdocs-material-9.5.13"><title>README - Homelab</title><link rel=stylesheet href=../../assets/stylesheets/main.7e359304.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../_static/custom.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script> <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../assets/javascripts/glightbox.min.js"></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=teal data-md-color-accent=purple> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#readme class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title=Homelab class="md-header__button md-logo" aria-label=Homelab data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m19 2-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5Z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Homelab </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> README </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=teal data-md-color-accent=purple aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=teal data-md-color-accent=lime aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18V6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-2.69L23.31 12 20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69Z"/></svg> </label> </form> <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/jsa4000/homelab-ops title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> jsa4000/homelab-ops </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Homelab </a> </li> <li class=md-tabs__item> <a href=../../blog/ class=md-tabs__link> Blog </a> </li> <li class=md-tabs__item> <a href=../../layers/messaging/keda/ class=md-tabs__link> Layers </a> </li> <li class=md-tabs__item> <a href=../../sbc/armbian/ class=md-tabs__link> Sbc </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../mkdocs/ class=md-tabs__link> Tools </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title=Homelab class="md-nav__button md-logo" aria-label=Homelab data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m19 2-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5Z"/></svg> </a> Homelab </label> <div class=md-nav__source> <a href=https://github.com/jsa4000/homelab-ops title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> jsa4000/homelab-ops </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Homelab </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Blog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../blog/ class=md-nav__link> <span class=md-ellipsis> Blog </span> </a> </li> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Archive </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Layers </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Layers </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex=0> <span class=md-ellipsis> Messaging </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> Messaging </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../layers/messaging/keda/ class=md-nav__link> <span class=md-ellipsis> Keda </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class=md-ellipsis> Networking </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Networking </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../layers/networking/cilium/ class=md-nav__link> <span class=md-ellipsis> Cilium </span> </a> </li> <li class=md-nav__item> <a href=../../layers/networking/ddns/ class=md-nav__link> <span class=md-ellipsis> DDNS (Dynamic DNS) </span> </a> </li> <li class=md-nav__item> <a href=../../layers/networking/metallb/ class=md-nav__link> <span class=md-ellipsis> Metallb </span> </a> </li> <li class=md-nav__item> <a href=../../layers/networking/nat/ class=md-nav__link> <span class=md-ellipsis> NAT (Network address translation) </span> </a> </li> <li class=md-nav__item> <a href=../../layers/networking/traefik/ class=md-nav__link> <span class=md-ellipsis> Traefik </span> </a> </li> <li class=md-nav__item> <a href=../../layers/networking/zigbee/ class=md-nav__link> <span class=md-ellipsis> Zigbee </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_3> <label class=md-nav__link for=__nav_3_3 id=__nav_3_3_label tabindex=0> <span class=md-ellipsis> Security </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> Security </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../layers/security/cert-manager/ class=md-nav__link> <span class=md-ellipsis> Cert Manager </span> </a> </li> <li class=md-nav__item> <a href=../../layers/security/external-secrets/ class=md-nav__link> <span class=md-ellipsis> External Secrets </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Sbc </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Sbc </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_1> <label class=md-nav__link for=__nav_4_1 id=__nav_4_1_label tabindex=0> <span class=md-ellipsis> Armbian </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_1_label aria-expanded=false> <label class=md-nav__title for=__nav_4_1> <span class="md-nav__icon md-icon"></span> Armbian </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../sbc/armbian/ class=md-nav__link> <span class=md-ellipsis> Installation </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2> <label class=md-nav__link for=__nav_4_2 id=__nav_4_2_label tabindex=0> <span class=md-ellipsis> Dietpi </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> Dietpi </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../sbc/dietpi/ class=md-nav__link> <span class=md-ellipsis> DietPi OS </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_3> <label class=md-nav__link for=__nav_4_3 id=__nav_4_3_label tabindex=0> <span class=md-ellipsis> Orangepi </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_3_label aria-expanded=false> <label class=md-nav__title for=__nav_4_3> <span class="md-nav__icon md-icon"></span> Orangepi </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../sbc/orangepi/ class=md-nav__link> <span class=md-ellipsis> Orange Pi OS </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5 checked> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex> <span class=md-ellipsis> Tools </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=true> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Tools </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../mkdocs/ class=md-nav__link> <span class=md-ellipsis> MkDocs </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_2> <label class=md-nav__link for=__nav_5_2 id=__nav_5_2_label tabindex=0> <span class=md-ellipsis> Ansible </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_2_label aria-expanded=false> <label class=md-nav__title for=__nav_5_2> <span class="md-nav__icon md-icon"></span> Ansible </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ansible/ class=md-nav__link> <span class=md-ellipsis> Ansible </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_3> <label class=md-nav__link for=__nav_5_3 id=__nav_5_3_label tabindex=0> <span class=md-ellipsis> Byor </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_3_label aria-expanded=false> <label class=md-nav__title for=__nav_5_3> <span class="md-nav__icon md-icon"></span> Byor </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../byor/ class=md-nav__link> <span class=md-ellipsis> Build my Radar </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_4> <label class=md-nav__link for=__nav_5_4 id=__nav_5_4_label tabindex=0> <span class=md-ellipsis> Certificates </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_4_label aria-expanded=false> <label class=md-nav__title for=__nav_5_4> <span class="md-nav__icon md-icon"></span> Certificates </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../certificates/ class=md-nav__link> <span class=md-ellipsis> Certificates </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_5> <label class=md-nav__link for=__nav_5_5 id=__nav_5_5_label tabindex=0> <span class=md-ellipsis> Devpod </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5_5> <span class="md-nav__icon md-icon"></span> Devpod </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../devpod/ class=md-nav__link> <span class=md-ellipsis> DevPod </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_6> <label class=md-nav__link for=__nav_5_6 id=__nav_5_6_label tabindex=0> <span class=md-ellipsis> Dns </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_6_label aria-expanded=false> <label class=md-nav__title for=__nav_5_6> <span class="md-nav__icon md-icon"></span> Dns </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../dns/ class=md-nav__link> <span class=md-ellipsis> DNS </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_7> <label class=md-nav__link for=__nav_5_7 id=__nav_5_7_label tabindex=0> <span class=md-ellipsis> Gitops </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_7_label aria-expanded=false> <label class=md-nav__title for=__nav_5_7> <span class="md-nav__icon md-icon"></span> Gitops </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../gitops/ class=md-nav__link> <span class=md-ellipsis> Gitops </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_8> <label class=md-nav__link for=__nav_5_8 id=__nav_5_8_label tabindex=0> <span class=md-ellipsis> Iam </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_8_label aria-expanded=false> <label class=md-nav__title for=__nav_5_8> <span class="md-nav__icon md-icon"></span> Iam </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../iam/ class=md-nav__link> <span class=md-ellipsis> IAM </span> </a> </li> <li class=md-nav__item> <a href=../iam/zidatel-commands/ class=md-nav__link> <span class=md-ellipsis> README </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_8_3> <label class=md-nav__link for=__nav_5_8_3 id=__nav_5_8_3_label tabindex=0> <span class=md-ellipsis> Service user jwt </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_5_8_3_label aria-expanded=false> <label class=md-nav__title for=__nav_5_8_3> <span class="md-nav__icon md-icon"></span> Service user jwt </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../iam/service-user-jwt/ class=md-nav__link> <span class=md-ellipsis> Call a Secured API Using JSON Web Token (JWT) Profile </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_8_4> <label class=md-nav__link for=__nav_5_8_4 id=__nav_5_8_4_label tabindex=0> <span class=md-ellipsis> Tofu </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_5_8_4_label aria-expanded=false> <label class=md-nav__title for=__nav_5_8_4> <span class="md-nav__icon md-icon"></span> Tofu </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../iam/tofu/ class=md-nav__link> <span class=md-ellipsis> OpenTofu </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_9> <label class=md-nav__link for=__nav_5_9 id=__nav_5_9_label tabindex=0> <span class=md-ellipsis> K3s </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_9_label aria-expanded=false> <label class=md-nav__title for=__nav_5_9> <span class="md-nav__icon md-icon"></span> K3s </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../k3s/ class=md-nav__link> <span class=md-ellipsis> K3s </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_10> <label class=md-nav__link for=__nav_5_10 id=__nav_5_10_label tabindex=0> <span class=md-ellipsis> Manifest </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_10_label aria-expanded=false> <label class=md-nav__title for=__nav_5_10> <span class="md-nav__icon md-icon"></span> Manifest </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../manifest/ class=md-nav__link> <span class=md-ellipsis> README </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_11 checked> <label class=md-nav__link for=__nav_5_11 id=__nav_5_11_label tabindex=0> <span class=md-ellipsis> Microceph </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_11_label aria-expanded=true> <label class=md-nav__title for=__nav_5_11> <span class="md-nav__icon md-icon"></span> Microceph </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> README </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> README </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#introduction class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> <nav class=md-nav aria-label=Introduction> <ul class=md-nav__list> <li class=md-nav__item> <a href=#rook-operator class=md-nav__link> <span class=md-ellipsis> Rook Operator </span> </a> </li> <li class=md-nav__item> <a href=#ceph class=md-nav__link> <span class=md-ellipsis> Ceph </span> </a> </li> <li class=md-nav__item> <a href=#rwo-vs-rwx class=md-nav__link> <span class=md-ellipsis> RWO vs RWX </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#microceph class=md-nav__link> <span class=md-ellipsis> MicroCeph </span> </a> <nav class=md-nav aria-label=MicroCeph> <ul class=md-nav__list> <li class=md-nav__item> <a href=#installation class=md-nav__link> <span class=md-ellipsis> Installation </span> </a> </li> <li class=md-nav__item> <a href=#notes class=md-nav__link> <span class=md-ellipsis> Notes </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#rook class=md-nav__link> <span class=md-ellipsis> Rook </span> </a> </li> <li class=md-nav__item> <a href=#lvm class=md-nav__link> <span class=md-ellipsis> LVM </span> </a> <nav class=md-nav aria-label=LVM> <ul class=md-nav__list> <li class=md-nav__item> <a href=#lvm-rook-ceph class=md-nav__link> <span class=md-ellipsis> LVM Rook-Ceph </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#references class=md-nav__link> <span class=md-ellipsis> References </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_12> <label class=md-nav__link for=__nav_5_12 id=__nav_5_12_label tabindex=0> <span class=md-ellipsis> Qemu </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_12_label aria-expanded=false> <label class=md-nav__title for=__nav_5_12> <span class="md-nav__icon md-icon"></span> Qemu </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../qemu/ class=md-nav__link> <span class=md-ellipsis> QEMU </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_13> <label class=md-nav__link for=__nav_5_13 id=__nav_5_13_label tabindex=0> <span class=md-ellipsis> Ssh </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_13_label aria-expanded=false> <label class=md-nav__title for=__nav_5_13> <span class="md-nav__icon md-icon"></span> Ssh </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ssh/ class=md-nav__link> <span class=md-ellipsis> SSH </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=readme>README</h1> <h2 id=introduction>Introduction</h2> <p><strong>Hyper-converged infrastructure (HCI)</strong> is a software-defined IT infrastructure that <code>virtualizes</code> all of the elements of conventional "hardware-defined" systems. HCI includes, at a minimum, virtualized computing (a hypervisor), software-defined storage, and virtualized networking (software-defined networking). HCI typically runs on commercial off-the-shelf (COTS) servers. The traditional silos of compute and storage resources can be wrapped up into a single hyper-converged appliance. Separate storage networks (SANs) and connections via network attached storage (NAS) disappear.</p> <p>There has been discussion around having suitable storage solution for Kubernetes and this discussion has always centred on the need that storage should be run as its own service, to be consumed by deployments, rather than built as part of them using native components. Although we have a few different storage services available, but may really not be suitable for what we want to achieve:</p> <ul> <li><strong>Cloud Storage</strong> - perfect for object storage, but not particularly performant and will usually require application refactoring.</li> <li><strong>Cloud Filestore</strong> - expensive but reliable and performant managed NFS solution.</li> <li><strong>Roll-your-own in Compute</strong> - the last resort of a desperate system admin. One can get lost for days trying to string a <code>GlusterFS</code> cluster together and then comes the headache when there's need to change it.</li> <li><strong>Vendor lock-in</strong> - some organizations that prefer to run their own self-manage Kubernetes cluster on-premises may not want to be locked into any cloud vendors and still wants a high-performing, highly scalable distributed storage system with no single point of failure.</li> </ul> <h3 id=rook-operator>Rook Operator</h3> <p>This is an <strong>operator</strong> and <strong>orchestrator</strong> for Kubernetes that automates the provisioning, configuration, scaling, migration and disaster recovery of storage. Rook supports several backend providers (such <code>ceph</code>, <code>cassandra</code>, etc.) and uses a consistent common framework across all of them. The Ceph provider for Rook is <strong>stable</strong> and <strong>production</strong> ready.</p> <p>Rook consists of multiple components:</p> <ul> <li><strong>Rook Operator</strong> is the core of Rook. The Rook operator is a simple container that automatically bootstraps the storage clusters and monitors the storage daemons to ensure the storage clusters are healthy.</li> <li><strong>Rook Agents</strong> run on each storage node and configure a FlexVolume plugin that integrates with Kubernetes' volume controller framework. Agents handle all storage operations such as attaching network storage devices, mounting volumes on the host, and formatting the filesystem.</li> <li><strong>Rook Discovers</strong> detect storage devices attached to the storage node.</li> </ul> <p>Rook also deploys <code>MON</code>, <code>OSD</code> and <code>MGR</code> daemons for the Ceph clusters as Kubernetes pods.</p> <p>The Rook Operator enables you to create and manage your storage clusters through CRDs. Each type of resource has its own CRD defined.</p> <ul> <li>A Rook Cluster provides the settings of the storage cluster to serve block, object stores, and shared file systems. Each cluster has multiple pools.</li> <li>A Pool manages the backing store for a block store. Pools are also used internally by object and file stores.</li> <li>An Object Store exposes storage with an S3-compatible interface.</li> <li>A File System provides shared storage for multiple Kubernetes pods.</li> <li>Rook Ceph provide <code>RWO</code> (<strong>CephRBD</strong>) and <code>RWX</code> (<strong>CephFS</strong>) volumes types. Also is support Object Storage via <strong>RADOS</strong> engine.</li> </ul> <h3 id=ceph>Ceph</h3> <p>Ceph is an open-source project that provides massively scalable, software-defined storage systems on commodity hardware. It can provide object, block or file system storage, and automatically distributes and replicates data across multiple storage nodes to guarantee no single point of failure.</p> <p>At its heart, Ceph is a distributed storage system engineered to carry out massive data management tasks, which it accomplishes through the use of the RADOS (Reliable Autonomic Distributed Object Store) system. Its architecture is designed to distribute data across various machines in a scalable fashion.</p> <p><a class=glightbox href=images/ceph-architecture.png data-type=image data-width=100% data-height=auto data-desc-position=bottom><img alt=Arch src=images/ceph-architecture.png></a></p> <p>Ceph consists of multiple components:</p> <ul> <li><strong>Ceph Monitors (MON)</strong> are responsible for forming cluster quorums. All the cluster nodes report to monitor nodes and share information about every change in their state.</li> <li><strong>Ceph Object Store Devices (OSD)</strong> are responsible for storing objects on local file systems and providing access to them over the network. Usually, one OSD daemon is tied to one physical disk in your cluster. Ceph clients interact with OSDs directly.</li> <li><strong>Ceph Manager (MGR)</strong> provides additional monitoring and interfaces to external monitoring and management systems.</li> <li><strong>Reliable Autonomic Distributed Object Stores (RADOS)</strong> are at the core of Ceph storage clusters. This layer makes sure that stored data always remains consistent and performs data replication, failure detection, and recovery among others.</li> </ul> <p>To read/write data from/to a Ceph cluster, a client will first contact Ceph MONs to obtain the most recent copy of their cluster map. The cluster map contains the cluster topology as well as the data storage locations. Ceph clients use the cluster map to figure out which OSD to interact with and initiate a connection with the associated OSD.</p> <p>Files stored in the disk (<code>images</code>) are converted into several objects. These objects are then distributed into <code>placement groups</code> (<code>pg</code>) which are put into <code>pools</code>. A <code>pool</code> has some properties configured as how many <code>replicas</code> of a <code>pg</code> will be stored in the cluster (3 by default). Those <code>pg</code> will finally be physically stored into an <code>Object Storage Daemon</code> (OSD). An <code>OSD</code> stores <code>pg</code> (and so the objects within it) and provides access to them over the network.</p> <p><a class=glightbox href=images/storage-architecture.png data-type=image data-width=100% data-height=auto data-desc-position=bottom><img alt=Arch src=images/storage-architecture.png></a></p> <p>There are two techniques in order to maintain the data spread for all the cluster, in order to ensure <code>high availability</code> and <code>disaster recovery</code>.</p> <ul> <li><strong>replication</strong>: this allows the OSD (disks) to be replicated over some other Ceph instances within the <strong>same</strong> cluster. This can be replication within the same <strong>Availability Zone</strong> but with separation of rack, netwrking, power suppliers, etc..</li> <li><strong>mirroring</strong>: this allows the OSD (disks) to be replicated over some other Ceph instances within <strong>different</strong> clusters. This can be different <strong>region</strong> for backups cluster for disaster Recove, so depending on metrics RTO or RPO decice the strategy to follow: BACKUP/Restore, Pilot Light, Warmup StandBy or Active/Passive, Active-Active.</li> <li><strong>Snapshot</strong>: Since an OSD is created by mounting a device (loop, partition, lvm, disk, etc..) you can take an snapshot or backup directly. Using Kubernetes and Rook, there is a native resource from Kubernetes (<code>snapshot.storage.k8s.io/v1</code>) that allows to create backups of the persistent volumes in order to perform maintenance task of other two methods fail.</li> </ul> <h3 id=rwo-vs-rwx>RWO vs RWX</h3> <p>Both volume types are supported by Kubernetes and Container Storage Interface (<strong>CSI</strong>), that is implemented by Ceph Rook.</p> <p>Basically <code>RWO</code> is <code>ReadWriteOnce</code>, that means only one Pod can Read or Write to that particular volume. However <code>RWX</code> is <code>ReadWriteMany</code>, that means a volume can be shared among multiple Pods.</p> <p>RWO vs RWX: An important difference is that the filesystem for <code>RWO</code> is <code>ext4</code> and for <code>RWX</code> is <code>nfs4</code>. As the <code>RWX</code> is using a <em>network file storage</em> (<strong>NFS</strong>), there will be a lot of overhead, which is only necessary to allow for such a remote storage.</p> <p>Following are some conclusions for standard benchmarks:</p> <ul> <li>RWX local vs remote, does not make a difference. Likely because the same calls are being made regardless.</li> <li>RWO local vs remote, for large and medium sized blocks there is a difference up to 30%, but no difference when the files get small.</li> <li>RWO vs RWX: Significant Difference of 50% or more in the duration! IOPS and Bandwidth are even up to 250% faster (might be too artificial, so not soo relevant). Difference of remote and local is as expected when using the data of the left plots.</li> </ul> <h2 id=microceph>MicroCeph</h2> <p>MicroCeph is the easiest way to get up and running with Ceph.</p> <p>MicroCeph is a lightweight way of deploying and managing a Ceph cluster. Ceph is a highly scalable, open-source distributed storage system designed to provide excellent performance, reliability, and flexibility for object, block, and file-level storage.</p> <p>Ceph cluster management is streamlined by simplifying key distribution, service placement, and disk administration for quick, effortless deployment and operations. This applies to clusters that span private clouds, edge clouds, as well as home labs and single workstations.</p> <p>MicroCeph is focused on providing a modern deployment and management experience to Ceph administrators and storage software developers.</p> <p><a class=glightbox href=images/microceph-architecture.png data-type=image data-width=100% data-height=auto data-desc-position=bottom><img alt=Arch src=images/microceph-architecture.png></a></p> <p>The microceph snap packages all the required ceph-binaries, dqlite and a small management daemon (microcephd) which ties all of this together. Using the light-weight distributed dqlite layer, MicroCeph enables orchestration of a ceph cluster in a centralised and easy to use manner.</p> <h3 id=installation>Installation</h3> <div class=highlight><pre><span></span><code><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=c1># Connect to the Servers</span>
<a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>ssh<span class=w> </span>ubuntu@localhost<span class=w> </span>-p<span class=w> </span><span class=m>50031</span>
<a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a>
<a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=w> </span><span class=c1># Install MicroCeph in servers</span>
<a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a>sudo<span class=w> </span>snap<span class=w> </span>install<span class=w> </span>microceph<span class=w> </span>--channel<span class=w> </span>latest/stable
<a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a>sudo<span class=w> </span>snap<span class=w> </span>connect<span class=w> </span>microceph:hardware-observe
<a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a>sudo<span class=w> </span>snap<span class=w> </span>connect<span class=w> </span>microceph:dm-crypt
<a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>sudo<span class=w> </span>snap<span class=w> </span>refresh<span class=w> </span>--hold<span class=w> </span>microceph
<a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>
<a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a><span class=c1># Check status (same outputs)</span>
<a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a>sudo<span class=w> </span>microceph.ceph<span class=w> </span>status
<a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a>sudo<span class=w> </span>ceph<span class=w> </span>status
<a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a>
<a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a><span class=c1># Configure MicroCeph and add nodes</span>
<a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a>
<a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a><span class=c1>#sudo microceph init # It Works because the IP can be changed to use different network interface</span>
<a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a><span class=c1>#sudo microceph cluster bootstrap # https://github.com/canonical/microceph/issues/197</span>
<a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a><span class=c1>#sudo microceph cluster bootstrap --mon-ip 192.168.205.101 --public-network 192.168.205.101/24 --cluster-network 192.168.205.101/24</span>
<a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a>
<a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a><span class=c1># Master Node</span>
<a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a><span class=nv>SERVER_IP</span><span class=o>=</span><span class=m>192</span>.168.205.101
<a id=__codelineno-0-22 name=__codelineno-0-22 href=#__codelineno-0-22></a><span class=nv>SERVER_MASTER</span><span class=o>=</span>yes
<a id=__codelineno-0-23 name=__codelineno-0-23 href=#__codelineno-0-23></a><span class=nv>SERVER_NAME</span><span class=o>=</span>server-1
<a id=__codelineno-0-24 name=__codelineno-0-24 href=#__codelineno-0-24></a><span class=nv>ADD_SERVER</span><span class=o>=</span>no
<a id=__codelineno-0-25 name=__codelineno-0-25 href=#__codelineno-0-25></a><span class=nv>ADD_DISK</span><span class=o>=</span>no
<a id=__codelineno-0-26 name=__codelineno-0-26 href=#__codelineno-0-26></a><span class=nb>printf</span><span class=w> </span><span class=s2>&quot;</span><span class=nv>$SERVER_IP</span><span class=s2>\n</span><span class=nv>$SERVER_MASTER</span><span class=s2>\n</span><span class=nv>$SERVER_NAME</span><span class=s2>\n</span><span class=nv>$ADD_SERVER</span><span class=s2>\n</span><span class=nv>$ADD_DISK</span><span class=s2>\n&quot;</span><span class=w> </span><span class=p>|</span><span class=w> </span>sudo<span class=w> </span>microceph<span class=w> </span>init
<a id=__codelineno-0-27 name=__codelineno-0-27 href=#__codelineno-0-27></a>
<a id=__codelineno-0-28 name=__codelineno-0-28 href=#__codelineno-0-28></a><span class=c1># Check the cluster status</span>
<a id=__codelineno-0-29 name=__codelineno-0-29 href=#__codelineno-0-29></a>sudo<span class=w> </span>ceph<span class=w> </span>status
<a id=__codelineno-0-30 name=__codelineno-0-30 href=#__codelineno-0-30></a>sudo<span class=w> </span>microceph<span class=w> </span>cluster<span class=w> </span>list
<a id=__codelineno-0-31 name=__codelineno-0-31 href=#__codelineno-0-31></a>
<a id=__codelineno-0-32 name=__codelineno-0-32 href=#__codelineno-0-32></a><span class=c1># Add Nodes</span>
<a id=__codelineno-0-33 name=__codelineno-0-33 href=#__codelineno-0-33></a>sudo<span class=w> </span>microceph<span class=w> </span>cluster<span class=w> </span>add<span class=w> </span>server-2
<a id=__codelineno-0-34 name=__codelineno-0-34 href=#__codelineno-0-34></a>sudo<span class=w> </span>microceph<span class=w> </span>cluster<span class=w> </span>add<span class=w> </span>server-3
<a id=__codelineno-0-35 name=__codelineno-0-35 href=#__codelineno-0-35></a>
<a id=__codelineno-0-36 name=__codelineno-0-36 href=#__codelineno-0-36></a><span class=c1># Join Nodes</span>
<a id=__codelineno-0-37 name=__codelineno-0-37 href=#__codelineno-0-37></a>
<a id=__codelineno-0-38 name=__codelineno-0-38 href=#__codelineno-0-38></a><span class=c1># Node 1</span>
<a id=__codelineno-0-39 name=__codelineno-0-39 href=#__codelineno-0-39></a><span class=nv>SERVER_IP</span><span class=o>=</span><span class=m>192</span>.168.205.102
<a id=__codelineno-0-40 name=__codelineno-0-40 href=#__codelineno-0-40></a><span class=nv>SERVER_MASTER</span><span class=o>=</span>no
<a id=__codelineno-0-41 name=__codelineno-0-41 href=#__codelineno-0-41></a><span class=nv>SERVER_TOKEN</span><span class=o>=</span><span class=nv>eyJuYW1lIjoic2VydmVyLTIiLCJzZWNyZXQiOiJjYjQ5ZDcwZmQ1MzRiZmNiOTg2Y2U3NjBlMWE4NmQwNGNmN2JiMGQ5MDhiZTdjMzEwNWY0ZmYzYTg3MmVkMjg5IiwiZmluZ2VycHJpbnQiOiI0YTcwMGRjYmFhYWZkZTJhN2YyMzFiM2MxMzU1MWRhZTg5MGM4ZTZkN2YzYjBmNzhkOGUyZjM1NzlmNWYwNmE4Iiwiam9pbl9hZGRyZXNzZXMiOlsiMTkyLjE2OC4yMDUuMTAxOjc0NDMiXX0</span><span class=o>=</span>
<a id=__codelineno-0-42 name=__codelineno-0-42 href=#__codelineno-0-42></a><span class=nv>ADD_DISK</span><span class=o>=</span>no
<a id=__codelineno-0-43 name=__codelineno-0-43 href=#__codelineno-0-43></a><span class=nb>printf</span><span class=w> </span><span class=s2>&quot;</span><span class=nv>$SERVER_IP</span><span class=s2>\n</span><span class=nv>$SERVER_MASTER</span><span class=s2>\n</span><span class=nv>$SERVER_TOKEN</span><span class=s2>\n</span><span class=nv>$ADD_DISK</span><span class=s2>\n&quot;</span><span class=w> </span><span class=p>|</span><span class=w> </span>sudo<span class=w> </span>microceph<span class=w> </span>init
<a id=__codelineno-0-44 name=__codelineno-0-44 href=#__codelineno-0-44></a>
<a id=__codelineno-0-45 name=__codelineno-0-45 href=#__codelineno-0-45></a><span class=c1># Node 2</span>
<a id=__codelineno-0-46 name=__codelineno-0-46 href=#__codelineno-0-46></a><span class=nv>SERVER_IP</span><span class=o>=</span><span class=m>192</span>.168.205.103
<a id=__codelineno-0-47 name=__codelineno-0-47 href=#__codelineno-0-47></a><span class=nv>SERVER_MASTER</span><span class=o>=</span>no
<a id=__codelineno-0-48 name=__codelineno-0-48 href=#__codelineno-0-48></a><span class=nv>SERVER_TOKEN</span><span class=o>=</span><span class=nv>eyJuYW1lIjoic2VydmVyLTMiLCJzZWNyZXQiOiIxOTBlMWM3YjhiNzA5YzA5ZjhmZGQzYWQxMDE2NzZiZmMyMzNiYTc3Yzc2Y2E5YjQzNjM2MzExZDYzMGZmNzRkIiwiZmluZ2VycHJpbnQiOiI0YTcwMGRjYmFhYWZkZTJhN2YyMzFiM2MxMzU1MWRhZTg5MGM4ZTZkN2YzYjBmNzhkOGUyZjM1NzlmNWYwNmE4Iiwiam9pbl9hZGRyZXNzZXMiOlsiMTkyLjE2OC4yMDUuMTAxOjc0NDMiXX0</span><span class=o>=</span>
<a id=__codelineno-0-49 name=__codelineno-0-49 href=#__codelineno-0-49></a><span class=nv>ADD_DISK</span><span class=o>=</span>no
<a id=__codelineno-0-50 name=__codelineno-0-50 href=#__codelineno-0-50></a><span class=nb>printf</span><span class=w> </span><span class=s2>&quot;</span><span class=nv>$SERVER_IP</span><span class=s2>\n</span><span class=nv>$SERVER_MASTER</span><span class=s2>\n</span><span class=nv>$SERVER_TOKEN</span><span class=s2>\n</span><span class=nv>$ADD_DISK</span><span class=s2>\n&quot;</span><span class=w> </span><span class=p>|</span><span class=w> </span>sudo<span class=w> </span>microceph<span class=w> </span>init
<a id=__codelineno-0-51 name=__codelineno-0-51 href=#__codelineno-0-51></a>
<a id=__codelineno-0-52 name=__codelineno-0-52 href=#__codelineno-0-52></a><span class=c1># Check the status</span>
<a id=__codelineno-0-53 name=__codelineno-0-53 href=#__codelineno-0-53></a>sudo<span class=w> </span>ceph<span class=w> </span>status
<a id=__codelineno-0-54 name=__codelineno-0-54 href=#__codelineno-0-54></a>sudo<span class=w> </span>microceph<span class=w> </span>cluster<span class=w> </span>list
<a id=__codelineno-0-55 name=__codelineno-0-55 href=#__codelineno-0-55></a><span class=c1># The status of the cluster must be HEALTH_OK</span>
<a id=__codelineno-0-56 name=__codelineno-0-56 href=#__codelineno-0-56></a>
<a id=__codelineno-0-57 name=__codelineno-0-57 href=#__codelineno-0-57></a><span class=c1># Enable RADOS Gateway (Object Storage)</span>
<a id=__codelineno-0-58 name=__codelineno-0-58 href=#__codelineno-0-58></a>sudo<span class=w> </span>microceph<span class=w> </span><span class=nb>enable</span><span class=w> </span>rgw
<a id=__codelineno-0-59 name=__codelineno-0-59 href=#__codelineno-0-59></a><span class=c1># Create Client Key and Client Secret</span>
<a id=__codelineno-0-60 name=__codelineno-0-60 href=#__codelineno-0-60></a>sudo<span class=w> </span>radosgw-admin<span class=w> </span>user<span class=w> </span>create<span class=w> </span>--uid<span class=o>=</span>myuser<span class=w> </span>--display-name<span class=o>=</span>myuser
<a id=__codelineno-0-61 name=__codelineno-0-61 href=#__codelineno-0-61></a>
<a id=__codelineno-0-62 name=__codelineno-0-62 href=#__codelineno-0-62></a><span class=c1># Enable Dashboard https://github.com/UtkarshBhatthere/microceph/blob/2cb0efaf57b5dd7d8328b2ff2891460b0da16125/docs/tutorial/enable_dashboard.rst</span>
<a id=__codelineno-0-63 name=__codelineno-0-63 href=#__codelineno-0-63></a>sudo<span class=w> </span>ceph<span class=w> </span>mgr<span class=w> </span>module<span class=w> </span><span class=nb>enable</span><span class=w> </span>dashboard
<a id=__codelineno-0-64 name=__codelineno-0-64 href=#__codelineno-0-64></a>sudo<span class=w> </span>ceph<span class=w> </span>dashboard<span class=w> </span>create-self-signed-cert
<a id=__codelineno-0-65 name=__codelineno-0-65 href=#__codelineno-0-65></a>sudo<span class=w> </span>ceph<span class=w> </span>mgr<span class=w> </span>services
<a id=__codelineno-0-66 name=__codelineno-0-66 href=#__codelineno-0-66></a>sudo<span class=w> </span>microceph.ceph<span class=w> </span>mgr<span class=w> </span>module<span class=w> </span>ls
<a id=__codelineno-0-67 name=__codelineno-0-67 href=#__codelineno-0-67></a>
<a id=__codelineno-0-68 name=__codelineno-0-68 href=#__codelineno-0-68></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;ubuntu1234&quot;</span><span class=w> </span>&gt;<span class=w> </span>ceph-pass.txt
<a id=__codelineno-0-69 name=__codelineno-0-69 href=#__codelineno-0-69></a>sudo<span class=w> </span>cp<span class=w> </span>~/ceph-pass.txt<span class=w> </span>/root/<span class=w>  </span><span class=c1>#Workaround for permissions</span>
<a id=__codelineno-0-70 name=__codelineno-0-70 href=#__codelineno-0-70></a>sudo<span class=w> </span>ceph<span class=w> </span>dashboard<span class=w> </span>ac-user-create<span class=w> </span>ubuntu<span class=w> </span>-i<span class=w> </span>/root/ceph-pass.txt<span class=w> </span>administrator
<a id=__codelineno-0-71 name=__codelineno-0-71 href=#__codelineno-0-71></a>
<a id=__codelineno-0-72 name=__codelineno-0-72 href=#__codelineno-0-72></a><span class=c1># (ubuntu/ubuntu1234)</span>
<a id=__codelineno-0-73 name=__codelineno-0-73 href=#__codelineno-0-73></a><span class=c1># http#s://192.168.205.101:8443/#/login?returnUrl=%2Fdashboard</span>
<a id=__codelineno-0-74 name=__codelineno-0-74 href=#__codelineno-0-74></a>
<a id=__codelineno-0-75 name=__codelineno-0-75 href=#__codelineno-0-75></a><span class=c1># Enable Prometheus in Ceph</span>
<a id=__codelineno-0-76 name=__codelineno-0-76 href=#__codelineno-0-76></a>sudo<span class=w> </span>ceph<span class=w> </span>mgr<span class=w> </span>module<span class=w> </span><span class=nb>enable</span><span class=w> </span>prometheus
<a id=__codelineno-0-77 name=__codelineno-0-77 href=#__codelineno-0-77></a>sudo<span class=w> </span>ceph<span class=w> </span>config<span class=w> </span><span class=nb>set</span><span class=w> </span>mgr<span class=w> </span>mgr/prometheus/server_addr<span class=w> </span><span class=m>192</span>.168.205.101
<a id=__codelineno-0-78 name=__codelineno-0-78 href=#__codelineno-0-78></a>sudo<span class=w> </span>ceph<span class=w> </span>config<span class=w> </span><span class=nb>set</span><span class=w> </span>mgr<span class=w> </span>mgr/prometheus/server_port<span class=w> </span><span class=m>30436</span>
<a id=__codelineno-0-79 name=__codelineno-0-79 href=#__codelineno-0-79></a>sudo<span class=w> </span>ceph<span class=w> </span>mgr<span class=w> </span>services
<a id=__codelineno-0-80 name=__codelineno-0-80 href=#__codelineno-0-80></a>
<a id=__codelineno-0-81 name=__codelineno-0-81 href=#__codelineno-0-81></a><span class=c1>#{</span>
<a id=__codelineno-0-82 name=__codelineno-0-82 href=#__codelineno-0-82></a><span class=c1>#    &quot;dashboard&quot;: &quot;https://192.168.205.101:8443/&quot;,</span>
<a id=__codelineno-0-83 name=__codelineno-0-83 href=#__codelineno-0-83></a><span class=c1>#    &quot;prometheus&quot;: &quot;http://192.168.205.101:9283/&quot;</span>
<a id=__codelineno-0-84 name=__codelineno-0-84 href=#__codelineno-0-84></a><span class=c1>#}</span>
<a id=__codelineno-0-85 name=__codelineno-0-85 href=#__codelineno-0-85></a>
<a id=__codelineno-0-86 name=__codelineno-0-86 href=#__codelineno-0-86></a><span class=c1># Alerts</span>
<a id=__codelineno-0-87 name=__codelineno-0-87 href=#__codelineno-0-87></a>sudo<span class=w> </span>ceph<span class=w> </span>dashboard<span class=w> </span>set-alertmanager-api-host<span class=w> </span><span class=s1>&#39;http://localhost:9093&#39;</span>
<a id=__codelineno-0-88 name=__codelineno-0-88 href=#__codelineno-0-88></a>sudo<span class=w> </span>ceph<span class=w> </span>dashboard<span class=w> </span>set-prometheus-api-host<span class=w> </span><span class=s1>&#39;http://192.168.205.101:30436&#39;</span><span class=w> </span><span class=c1># Through ingress, load balancer or NodePort (not recommended)</span>
<a id=__codelineno-0-89 name=__codelineno-0-89 href=#__codelineno-0-89></a>sudo<span class=w> </span>ceph<span class=w> </span>dashboard<span class=w> </span>set-prometheus-api-ssl-verify<span class=w> </span>False
<a id=__codelineno-0-90 name=__codelineno-0-90 href=#__codelineno-0-90></a>sudo<span class=w> </span>ceph<span class=w> </span>dashboard<span class=w> </span>set-alertmanager-api-ssl-verify<span class=w> </span>False
<a id=__codelineno-0-91 name=__codelineno-0-91 href=#__codelineno-0-91></a>
<a id=__codelineno-0-92 name=__codelineno-0-92 href=#__codelineno-0-92></a><span class=c1># Upgrade MicroCeph (https://github.com/canonical/microceph/blob/main/docs/how-to/reef-upgrade.rst)</span>
<a id=__codelineno-0-93 name=__codelineno-0-93 href=#__codelineno-0-93></a>sudo<span class=w> </span>snap<span class=w> </span>refresh<span class=w> </span>microceph<span class=w> </span>--channel<span class=w> </span>reef/stable
<a id=__codelineno-0-94 name=__codelineno-0-94 href=#__codelineno-0-94></a>
<a id=__codelineno-0-95 name=__codelineno-0-95 href=#__codelineno-0-95></a><span class=c1># Uninstall MicroCeph</span>
<a id=__codelineno-0-96 name=__codelineno-0-96 href=#__codelineno-0-96></a>sudo<span class=w> </span>snap<span class=w> </span>remove<span class=w> </span>microceph
</code></pre></div> <p>Main cluster Configuration and commands</p> <div class=highlight><pre><span></span><code><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>sudo<span class=w> </span>microceph<span class=w> </span>cluster<span class=w> </span>config<span class=w> </span>list
<a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a>sudo<span class=w> </span>microceph<span class=w> </span>cluster<span class=w> </span>config<span class=w> </span><span class=nb>set</span><span class=w> </span>cluster_network<span class=w> </span><span class=m>192</span>.168.205.0/24
<a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>sudo<span class=w> </span>microceph<span class=w> </span>cluster<span class=w> </span>config<span class=w> </span>reset<span class=w> </span>cluster_network
<a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>
<a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a>sudo<span class=w> </span>microceph<span class=w> </span>cluster<span class=w> </span>list
<a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a>sudo<span class=w> </span>microceph<span class=w> </span>cluster<span class=w> </span>remove<span class=w> </span>server-1
<a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a>sudo<span class=w> </span>microceph<span class=w> </span>cluster<span class=w> </span>add<span class=w> </span>server-2
<a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a>sudo<span class=w> </span>microceph<span class=w> </span>cluster<span class=w> </span>add<span class=w> </span>server-3
<a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a>
<a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a><span class=nb>echo</span><span class=w> </span><span class=nv>eyJuYW1lIjoic2VydmVyLTMiLCJzZWNyZXQiOiIzMTM1Y2JmNzE0MTQ1NzYzNDdkNmY2ODllZjJiNWY1MGU5NWI0MjA0MzhhZDQxNTg4MzlmN2RlODhmZTViMTZlIiwiZmluZ2VycHJpbnQiOiI5NWM4MjhjN2E2NGNjZDYzYWM3OWNjZGFkNWVkNmFmMjQzZDFkMmUzODZjMGE2NzYyMDk3OTA2ZjM0NmY5YmU5Iiwiam9pbl9hZGRyZXNzZXMiOlsiMTkyLjE2OC4yMDUuMTAxOjc0NDMiLCIxMC4wLjIuMTU6NzQ0MyJdfQ</span><span class=o>==</span><span class=w> </span><span class=p>|</span><span class=w> </span>base64<span class=w> </span>-d<span class=w> </span><span class=p>|</span><span class=w> </span>jq<span class=w> </span>.
<a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a>
<a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a>sudo<span class=w> </span>microceph<span class=w> </span>cluster<span class=w> </span>join<span class=w>  </span><span class=nv>eyJuYW1lIjoic2VydmVyLTMiLCJzZWNyZXQiOiIzMTM1Y2JmNzE0MTQ1NzYzNDdkNmY2ODllZjJiNWY1MGU5NWI0MjA0MzhhZDQxNTg4MzlmN2RlODhmZTViMTZlIiwiZmluZ2VycHJpbnQiOiI5NWM4MjhjN2E2NGNjZDYzYWM3OWNjZGFkNWVkNmFmMjQzZDFkMmUzODZjMGE2NzYyMDk3OTA2ZjM0NmY5YmU5Iiwiam9pbl9hZGRyZXNzZXMiOlsiMTkyLjE2OC4yMDUuMTAxOjc0NDMiLCIxMC4wLjIuMTU6NzQ0MyJdfQ</span><span class=o>==</span>
</code></pre></div> <p>Basic Ceph configuration commands.</p> <div class=highlight><pre><span></span><code><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a>sudo<span class=w> </span>microceph.ceph<span class=w> </span>status
<a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a>sudo<span class=w> </span>ceph<span class=w> </span>status
<a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a>
<a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a>sudo<span class=w> </span>microceph.ceph<span class=w> </span>config<span class=w> </span>dump
<a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a>sudo<span class=w> </span>microceph.ceph<span class=w> </span>mon<span class=w> </span>dump
<a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a>sudo<span class=w> </span>microceph.ceph<span class=w> </span>osd<span class=w> </span>dump
<a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a>
<a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>lspools
<a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>tree
<a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a>
<a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a>cat<span class=w> </span>/var/snap/microceph/current/conf/ceph.conf
<a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a>cat<span class=w> </span>/var/snap/microceph/current/conf/keyring.conf
<a id=__codelineno-2-13 name=__codelineno-2-13 href=#__codelineno-2-13></a>sudo<span class=w> </span>ss<span class=w> </span>-tlnp<span class=w> </span><span class=p>|</span><span class=w> </span>grep<span class=w> </span>mon
</code></pre></div> <p>Create a complex Ceph configuration, use an BD pool backed by specific OSDs (e.g. tenant separation, use only SSD disks, ...)</p> <div class=highlight><pre><span></span><code><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=c1># Create Crush Rule</span>
<a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>crush<span class=w> </span>rule<span class=w> </span>create-replicated<span class=w> </span>my_replicated_ssd_rule<span class=w> </span>default<span class=w> </span>host<span class=w> </span>ssd
<a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a>
<a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a><span class=c1>#Create a new pool</span>
<a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a>sudo<span class=w> </span>rbd<span class=w> </span>pool<span class=w> </span>create<span class=w> </span>my-ssd-pool
<a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a>
<a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a><span class=c1># Set The Crash Rule to the pool</span>
<a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>pool<span class=w> </span><span class=nb>set</span><span class=w> </span>my-ssd-pool<span class=w> </span>crush_rule<span class=w> </span>my_replicated_ssd_rule
<a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a>
<a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a><span class=c1># Finally, configure rook-ceph CRDs to use the new created `my-ssd-pool`with custom rules</span>
</code></pre></div> <p>Create RDB (Rados Data Block) Pool</p> <div class=highlight><pre><span></span><code><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=c1># https://docs.ceph.com/en/latest/rados/operations/pools/</span>
<a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=c1># Pool names beginning with . are reserved for use by Ceph&#39;s internal operations. Do not create or manipulate pools with these names.</span>
<a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a>
<a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>pool<span class=w> </span>create<span class=w> </span>default.pool<span class=w> </span>replicated
<a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>pool<span class=w> </span><span class=nb>set</span><span class=w> </span>default.pool<span class=w> </span>size<span class=w> </span><span class=m>3</span>
<a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>pool<span class=w> </span><span class=nb>set</span><span class=w> </span>default.pool<span class=w> </span>min_size<span class=w> </span><span class=m>2</span>
<a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>pool<span class=w> </span><span class=nb>set</span><span class=w> </span>default.pool<span class=w> </span>pg_autoscale_mode<span class=w> </span>on
<a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>sudo<span class=w> </span>sudo<span class=w> </span>rbd<span class=w> </span>pool<span class=w> </span>init<span class=w> </span>default.pool
<a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a>
<a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a>
<a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a><span class=c1># Get list pools</span>
<a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>pool<span class=w> </span>ls
<a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>pool<span class=w> </span>ls<span class=w> </span>detail<span class=w> </span>--format<span class=w> </span>json-pretty
<a id=__codelineno-4-14 name=__codelineno-4-14 href=#__codelineno-4-14></a>
<a id=__codelineno-4-15 name=__codelineno-4-15 href=#__codelineno-4-15></a><span class=c1>#Pool types</span>
<a id=__codelineno-4-16 name=__codelineno-4-16 href=#__codelineno-4-16></a><span class=c1>#  The replicated pools require more raw storage but can implement all Ceph operations.</span>
<a id=__codelineno-4-17 name=__codelineno-4-17 href=#__codelineno-4-17></a><span class=c1>#  The erasure pools require less raw storage but can perform only some Ceph tasks and may provide decreased performance.</span>
<a id=__codelineno-4-18 name=__codelineno-4-18 href=#__codelineno-4-18></a>
<a id=__codelineno-4-19 name=__codelineno-4-19 href=#__codelineno-4-19></a><span class=c1># Replicated Block</span>
<a id=__codelineno-4-20 name=__codelineno-4-20 href=#__codelineno-4-20></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>pool<span class=w> </span>create<span class=w> </span><span class=o>{</span>pool-name<span class=o>}</span><span class=w> </span><span class=o>[{</span>pg-num<span class=o>}</span><span class=w> </span><span class=o>[{</span>pgp-num<span class=o>}]]</span><span class=w> </span><span class=o>[</span>replicated<span class=o>]</span><span class=w> </span><span class=o>[</span>crush-rule-name<span class=o>]</span><span class=w> </span><span class=o>[</span>expected-num-objects<span class=o>]</span>
<a id=__codelineno-4-21 name=__codelineno-4-21 href=#__codelineno-4-21></a>
<a id=__codelineno-4-22 name=__codelineno-4-22 href=#__codelineno-4-22></a><span class=c1># Erasure Block (Better performance for anti-corruption)</span>
<a id=__codelineno-4-23 name=__codelineno-4-23 href=#__codelineno-4-23></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>pool<span class=w> </span>create<span class=w> </span><span class=o>{</span>pool-name<span class=o>}</span><span class=w> </span><span class=o>[{</span>pg-num<span class=o>}</span><span class=w> </span><span class=o>[{</span>pgp-num<span class=o>}]]</span><span class=w> </span><span class=o>[</span>erasure<span class=o>]</span><span class=w> </span><span class=se>\</span>
<a id=__codelineno-4-24 name=__codelineno-4-24 href=#__codelineno-4-24></a><span class=w>         </span><span class=o>[</span>erasure-code-profile<span class=o>]</span><span class=w> </span><span class=o>[</span>crush-rule-name<span class=o>]</span><span class=w> </span><span class=o>[</span>expected_num_objects<span class=o>]</span><span class=w> </span><span class=o>[</span>--autoscale-mode<span class=o>=</span>&lt;on,off,warn&gt;<span class=o>]</span>
</code></pre></div> <p>CephFS for RWX support</p> <div class=highlight><pre><span></span><code><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=c1># https://docs.ceph.com/en/quincy/cephfs/createfs/</span>
<a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>pool<span class=w> </span>create<span class=w> </span>default.cephfs.data
<a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>pool<span class=w> </span>create<span class=w> </span>default.cephfs.metadata
<a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a>sudo<span class=w> </span>ceph<span class=w> </span>fs<span class=w> </span>new<span class=w> </span>default.cephfs<span class=w> </span>default.cephfs.metadata<span class=w> </span>default.cephfs.data
<a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a>sudo<span class=w> </span>ceph<span class=w> </span>fs<span class=w> </span><span class=nb>set</span><span class=w> </span>default.cephfs<span class=w> </span>allow_standby_replay<span class=w> </span><span class=m>1</span>
<a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a>
<a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a><span class=c1># Get application from CephFs</span>
<a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>pool<span class=w> </span>application<span class=w> </span>get<span class=w> </span>cephfs_data<span class=w> </span>cephfs
<a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>pool<span class=w> </span>application<span class=w> </span>get<span class=w> </span>cephfs_metadata<span class=w> </span>cephfs
<a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a>
<a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a><span class=c1># erasure Pool https://docs.ceph.com/en/latest/rados/operations/erasure-code/</span>
<a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>pool<span class=w> </span>create<span class=w> </span>ecpool<span class=w> </span>erasure
<a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a>sudo<span class=w> </span>ceph<span class=w> </span>osd<span class=w> </span>pool<span class=w> </span><span class=nb>set</span><span class=w> </span>cephfs_data<span class=w> </span>allow_ec_overwrites<span class=w> </span><span class=nb>true</span>
<a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a>
<a id=__codelineno-5-15 name=__codelineno-5-15 href=#__codelineno-5-15></a><span class=c1>#Create FS volume</span>
<a id=__codelineno-5-16 name=__codelineno-5-16 href=#__codelineno-5-16></a>sudo<span class=w> </span>ceph<span class=w> </span>fs<span class=w> </span>volume<span class=w> </span>create<span class=w> </span>mmy-cephfso
<a id=__codelineno-5-17 name=__codelineno-5-17 href=#__codelineno-5-17></a>
<a id=__codelineno-5-18 name=__codelineno-5-18 href=#__codelineno-5-18></a><span class=c1>#Get the status from CephFS</span>
<a id=__codelineno-5-19 name=__codelineno-5-19 href=#__codelineno-5-19></a>sudo<span class=w> </span>ceph<span class=w> </span>fs<span class=w> </span>status
<a id=__codelineno-5-20 name=__codelineno-5-20 href=#__codelineno-5-20></a>
<a id=__codelineno-5-21 name=__codelineno-5-21 href=#__codelineno-5-21></a><span class=c1># Configure Rook-Ceph</span>
</code></pre></div> <p>Add loop devices to Cepg</p> <div class=highlight><pre><span></span><code><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=c1># Three OSDs will be required to form a minimal Ceph cluster. In a production system, typically we would assign a physical block device to an OSD.</span>
<a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=c1>#  This means that, on each of the three machines, one entire disk must be allocated for storage or in single installation three OSD in the same machine</span>
<a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a><span class=c1># This will create a file backed OSDs.</span>
<a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a>sudo<span class=w> </span>microceph<span class=w> </span>disk<span class=w> </span>add<span class=w> </span>loop,4G,1
<a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>
<a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a><span class=c1>#Repeat the same in other cluster for redundancy and replication</span>
<a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a>sudo<span class=w> </span>microceph<span class=w> </span>disk<span class=w> </span>list
</code></pre></div> <p>The following loop creates three files under /mnt that will back respective loop devices. Each Virtual disk is then added as an OSD to Ceph, but the need to be added at /etc/fstab in order the be recognized at startup.</p> <div class=highlight><pre><span></span><code><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=c1># Create loop device at /mnt folder</span>
<a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>sudo<span class=w> </span>mktemp<span class=w> </span>-p<span class=w> </span>/mnt<span class=w> </span>XXXX.img<span class=w> </span><span class=c1># /mnt/IICQ.img</span>
<a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a>sudo<span class=w> </span>truncate<span class=w> </span>-s<span class=w> </span>1G<span class=w> </span><span class=s2>&quot;IICQ.img&quot;</span><span class=w> </span><span class=c1>#Expand to 1Gb</span>
<a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>sudo<span class=w> </span>losetup<span class=w> </span>--show<span class=w> </span>-f<span class=w> </span>IICQ.img<span class=w> </span><span class=c1># /dev/loop3</span>
<a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=c1># the block-devices plug doesn&#39;t allow accessing &#39;/dev/loopX&#39; devices so we make those same devices available under alternate names &#39;/dev/sdiY&#39;</span>
<a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a>sudo<span class=w> </span>mknod<span class=w> </span>-m<span class=w> </span><span class=m>0660</span><span class=w> </span><span class=s2>&quot;/dev/sdia&quot;</span><span class=w> </span>b<span class=w> </span><span class=m>7</span><span class=w> </span><span class=m>3</span><span class=w> </span><span class=c1># number 3 is X from /dev/loopX</span>
<a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>
<a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a><span class=c1># Add device to Ceph</span>
<a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a><span class=c1># For each Disk Ceph will create an OSD</span>
<a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a><span class=c1># In total it will create 9 OSD and 3 disk per server</span>
<a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a>sudo<span class=w> </span>microceph<span class=w> </span>disk<span class=w> </span>add<span class=w> </span>--wipe<span class=w> </span><span class=s2>&quot;/dev/sdi</span><span class=si>${</span><span class=nv>l</span><span class=si>}</span><span class=s2>&quot;</span>
<a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a>
<a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a><span class=c1># List Block Devices</span>
<a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a>lsblk
<a id=__codelineno-7-15 name=__codelineno-7-15 href=#__codelineno-7-15></a>losetup<span class=w> </span>-a<span class=w>  </span><span class=c1># list loop devices</span>
<a id=__codelineno-7-16 name=__codelineno-7-16 href=#__codelineno-7-16></a>sudo<span class=w> </span>microceph<span class=w> </span>disk<span class=w> </span>list
<a id=__codelineno-7-17 name=__codelineno-7-17 href=#__codelineno-7-17></a>sudo<span class=w> </span>ceph<span class=w> </span>mgr<span class=w> </span>services
<a id=__codelineno-7-18 name=__codelineno-7-18 href=#__codelineno-7-18></a>
<a id=__codelineno-7-19 name=__codelineno-7-19 href=#__codelineno-7-19></a><span class=c1># Detach from loop devices and remove from /dev</span>
<a id=__codelineno-7-20 name=__codelineno-7-20 href=#__codelineno-7-20></a>sudo<span class=w> </span>microceph<span class=w> </span>disk<span class=w> </span>remove<span class=w> </span>/dev/sdia
<a id=__codelineno-7-21 name=__codelineno-7-21 href=#__codelineno-7-21></a>sudo<span class=w> </span>microceph<span class=w> </span>disk<span class=w> </span>remove<span class=w> </span>/dev/sdib
<a id=__codelineno-7-22 name=__codelineno-7-22 href=#__codelineno-7-22></a>sudo<span class=w> </span>losetup<span class=w> </span>-d<span class=w> </span>/dev/loop3
<a id=__codelineno-7-23 name=__codelineno-7-23 href=#__codelineno-7-23></a>sudo<span class=w> </span>losetup<span class=w> </span>-d<span class=w> </span>/dev/loop4
<a id=__codelineno-7-24 name=__codelineno-7-24 href=#__codelineno-7-24></a>sudo<span class=w> </span>rm<span class=w> </span>-rf<span class=w> </span>/dev/sdia
<a id=__codelineno-7-25 name=__codelineno-7-25 href=#__codelineno-7-25></a>sudo<span class=w> </span>rm<span class=w> </span>-rf<span class=w> </span>/dev/sdib
</code></pre></div> <p>Following script creates three disks on each server of Ceph cluster</p> <div class=highlight><pre><span></span><code><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=c1>############</span>
<a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=c1># Script</span>
<a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a><span class=c1>############</span>
<a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a><span class=c1># Script to create 1Gb loop devices: /dev/sdia,/dev/sdib,/dev/sdic</span>
<a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a><span class=k>for</span><span class=w> </span>l<span class=w> </span><span class=k>in</span><span class=w> </span>a<span class=w> </span>b<span class=w> </span>c<span class=p>;</span><span class=w> </span><span class=k>do</span>
<a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a><span class=w>  </span><span class=nv>loop_file</span><span class=o>=</span><span class=s2>&quot;</span><span class=k>$(</span>sudo<span class=w> </span>mktemp<span class=w> </span>-p<span class=w> </span>/mnt<span class=w> </span>XXXX.img<span class=k>)</span><span class=s2>&quot;</span>
<a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a><span class=w>  </span>sudo<span class=w> </span>truncate<span class=w> </span>-s<span class=w> </span>1G<span class=w> </span><span class=s2>&quot;</span><span class=si>${</span><span class=nv>loop_file</span><span class=si>}</span><span class=s2>&quot;</span>
<a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a><span class=w>  </span><span class=nv>loop_dev</span><span class=o>=</span><span class=s2>&quot;</span><span class=k>$(</span>sudo<span class=w> </span>losetup<span class=w> </span>--show<span class=w> </span>-f<span class=w> </span><span class=s2>&quot;</span><span class=si>${</span><span class=nv>loop_file</span><span class=si>}</span><span class=s2>&quot;</span><span class=k>)</span><span class=s2>&quot;</span>
<a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a><span class=w>  </span><span class=c1># the block-devices plug doesn&#39;t allow accessing /dev/loopX</span>
<a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a><span class=w>  </span><span class=c1># devices so we make those same devices available under alternate</span>
<a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a><span class=w>  </span><span class=c1># names (/dev/sdiY)</span>
<a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a><span class=w>  </span><span class=nv>minor</span><span class=o>=</span><span class=s2>&quot;</span><span class=si>${</span><span class=nv>loop_dev</span><span class=p>##/dev/loop</span><span class=si>}</span><span class=s2>&quot;</span>
<a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a><span class=w>  </span>sudo<span class=w> </span>mknod<span class=w> </span>-m<span class=w> </span><span class=m>0660</span><span class=w> </span><span class=s2>&quot;/dev/sdi</span><span class=si>${</span><span class=nv>l</span><span class=si>}</span><span class=s2>&quot;</span><span class=w> </span>b<span class=w> </span><span class=m>7</span><span class=w> </span><span class=s2>&quot;</span><span class=si>${</span><span class=nv>minor</span><span class=si>}</span><span class=s2>&quot;</span>
<a id=__codelineno-8-14 name=__codelineno-8-14 href=#__codelineno-8-14></a><span class=w>  </span>sudo<span class=w> </span>microceph<span class=w> </span>disk<span class=w> </span>add<span class=w> </span>--wipe<span class=w> </span><span class=s2>&quot;/dev/sdi</span><span class=si>${</span><span class=nv>l</span><span class=si>}</span><span class=s2>&quot;</span><span class=w> </span><span class=c1># --encrypt</span>
<a id=__codelineno-8-15 name=__codelineno-8-15 href=#__codelineno-8-15></a><span class=w>  </span><span class=c1># to be permanent add the device into /etc/fstab</span>
<a id=__codelineno-8-16 name=__codelineno-8-16 href=#__codelineno-8-16></a><span class=w>  </span><span class=c1># /path/to/file       /path/to/mount       ext4       loop       0 0</span>
<a id=__codelineno-8-17 name=__codelineno-8-17 href=#__codelineno-8-17></a><span class=k>done</span>
<a id=__codelineno-8-18 name=__codelineno-8-18 href=#__codelineno-8-18></a>
<a id=__codelineno-8-19 name=__codelineno-8-19 href=#__codelineno-8-19></a><span class=c1># Get disks</span>
<a id=__codelineno-8-20 name=__codelineno-8-20 href=#__codelineno-8-20></a>sudo<span class=w> </span>microceph<span class=w> </span>disk<span class=w> </span>list
<a id=__codelineno-8-21 name=__codelineno-8-21 href=#__codelineno-8-21></a>sudo<span class=w> </span>ceph<span class=w> </span>mgr<span class=w> </span>services
<a id=__codelineno-8-22 name=__codelineno-8-22 href=#__codelineno-8-22></a>
<a id=__codelineno-8-23 name=__codelineno-8-23 href=#__codelineno-8-23></a>df
</code></pre></div> <p>Test the replication</p> <div class=highlight><pre><span></span><code><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=c1># Mount of the loop devices</span>
<a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a>sudo<span class=w> </span>mount<span class=w> </span>/dev/sdia<span class=w> </span>/mnt/<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span>sudo<span class=w> </span>sync
<a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a>
<a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=c1>#Unmount device</span>
<a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a>sudo<span class=w> </span>umount<span class=w> </span>/mnt/<span class=w>  </span><span class=o>&amp;&amp;</span><span class=w> </span>sudo<span class=w> </span>sync
</code></pre></div> <h3 id=notes>Notes</h3> <p>[https://discuss.linuxcontainers.org/t/microceph-vs-cephadm-microceph-partition-fix/18976]</p> <p>I've been experimenting with microceph &amp; more briefly with cephadm (with services running in podman) on a 5 x node "low end" cluster - these details are probably more interesting for people with nodes having single disks who still want to run ceph. TLDR - I'm going to be using microceph for various reasons:</p> <ul> <li>For your cluster you want at least 2 x NIC's ideally with a 10gb or greater internal network for ceph</li> <li>5 x node clusters will have better performance 1 than 3 x node clusters.</li> <li>microceph uses around 1.5gb of RAM on monitor nodes &amp; 500mb on the other nodes</li> <li>microceph clusters reboot much faster (less than 10 seconds on nvme) - than cephadm nodes (the services in podman took much longer to stop - 30 to 60 * seconds or so)</li> <li>cephadm uses a lot more disk (as it's running a complete Centos 8 stream system in each container) - RAM usage was similar to microceph</li> <li>cephadm will not install directly onto partitions - it requires lvm lv's</li> <li>install podman then apt install cephadm --no-install-recommends (to avoid pulling in docker) - ubuntu 23.10 gives you podman v4 from the official repos * now. You probably want to use docker with cephadm - my cephadm cluster never became healthy (mgr kept crashing - possibly due to using podman ?)</li> <li>Rather than going by the microceph docs - use microceph init to initialise every node so you can choose the specific ip address to run ceph on (otherwise * by default it will use your public interfaces)</li> </ul> <h2 id=rook>Rook</h2> <div class=highlight><pre><span></span><code><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=c1># https://www.mrajanna.com/setup-external-ceph-with-rook/</span>
<a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=c1># https://medium.com/techlogs/configuring-rook-with-external-ceph-6b4b49626112</span>
<a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a><span class=c1># https://blog.mymware.com/2022/11/02/rook-ceph-survguide.html</span>
<a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a><span class=c1># https://www.youtube.com/watch?v=-7hpXFs7au8</span>
<a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a>
<a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a><span class=c1># Connect to the Servers</span>
<a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a>ssh<span class=w> </span>ubuntu@localhost<span class=w> </span>-p<span class=w> </span><span class=m>50031</span>
<a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a>
<a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a><span class=c1>##################################</span>
<a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a><span class=c1># Automatic</span>
<a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a><span class=c1>##################################</span>
<a id=__codelineno-10-12 name=__codelineno-10-12 href=#__codelineno-10-12></a>
<a id=__codelineno-10-13 name=__codelineno-10-13 href=#__codelineno-10-13></a>sudo<span class=w> </span>microceph.ceph<span class=w> </span>mon<span class=w> </span>dump
<a id=__codelineno-10-14 name=__codelineno-10-14 href=#__codelineno-10-14></a>sudo<span class=w> </span>ceph<span class=w> </span>auth<span class=w> </span>get-key<span class=w> </span>client.admin
<a id=__codelineno-10-15 name=__codelineno-10-15 href=#__codelineno-10-15></a>sudo<span class=w> </span>ceph<span class=w> </span>auth<span class=w> </span>get-or-create<span class=w> </span>client.kubernetes2
<a id=__codelineno-10-16 name=__codelineno-10-16 href=#__codelineno-10-16></a>sudo<span class=w> </span>ceph<span class=w> </span>auth<span class=w> </span>get-or-create<span class=w> </span>client.csi-rbd-provisioner2
<a id=__codelineno-10-17 name=__codelineno-10-17 href=#__codelineno-10-17></a>
<a id=__codelineno-10-18 name=__codelineno-10-18 href=#__codelineno-10-18></a><span class=c1># Check the following links to import external Ceph cluster</span>
<a id=__codelineno-10-19 name=__codelineno-10-19 href=#__codelineno-10-19></a><span class=c1># https://rook.io/docs/rook/latest-release/CRDs/Cluster/external-cluster/?h=external#import-the-source-data</span>
<a id=__codelineno-10-20 name=__codelineno-10-20 href=#__codelineno-10-20></a><span class=c1># https://rook.io/docs/rook/latest-release/CRDs/Cluster/external-cluster/#1-create-all-users-and-keys</span>
<a id=__codelineno-10-21 name=__codelineno-10-21 href=#__codelineno-10-21></a><span class=c1># https://github.com/canonical/microk8s-core-addons/blob/main/addons/rook-ceph/plugin/connect-external-ceph</span>
<a id=__codelineno-10-22 name=__codelineno-10-22 href=#__codelineno-10-22></a><span class=c1># https://github.com/rook/rook/issues/11157</span>
<a id=__codelineno-10-23 name=__codelineno-10-23 href=#__codelineno-10-23></a>
<a id=__codelineno-10-24 name=__codelineno-10-24 href=#__codelineno-10-24></a>sudo<span class=w> </span>apt<span class=w> </span>install<span class=w> </span>jq<span class=w> </span>vim<span class=w> </span>htop<span class=w> </span>-y
<a id=__codelineno-10-25 name=__codelineno-10-25 href=#__codelineno-10-25></a>sudo<span class=w> </span>apt-get<span class=w> </span>install<span class=w> </span>python3-rbd<span class=w> </span>python3-rados<span class=w> </span>-y
<a id=__codelineno-10-26 name=__codelineno-10-26 href=#__codelineno-10-26></a>wget<span class=w> </span>https://raw.githubusercontent.com/rook/rook/master/deploy/examples/create-external-cluster-resources.py
<a id=__codelineno-10-27 name=__codelineno-10-27 href=#__codelineno-10-27></a>
<a id=__codelineno-10-28 name=__codelineno-10-28 href=#__codelineno-10-28></a>sudo<span class=w> </span>python3<span class=w> </span>create-external-cluster-resources.py<span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-29 name=__codelineno-10-29 href=#__codelineno-10-29></a><span class=w>  </span>--namespace<span class=w> </span>rook-ceph<span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-30 name=__codelineno-10-30 href=#__codelineno-10-30></a><span class=w>  </span>--ceph-conf<span class=o>=</span>/var/snap/microceph/current/conf/ceph.conf<span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-31 name=__codelineno-10-31 href=#__codelineno-10-31></a><span class=w>  </span>--keyring<span class=o>=</span>/var/snap/microceph/current/conf/ceph.keyring<span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-32 name=__codelineno-10-32 href=#__codelineno-10-32></a><span class=w>  </span>--rbd-data-pool-name<span class=w> </span>default.pool<span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-33 name=__codelineno-10-33 href=#__codelineno-10-33></a><span class=w>  </span>--cephfs-filesystem-name<span class=w> </span>default.cephfs<span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-34 name=__codelineno-10-34 href=#__codelineno-10-34></a><span class=w>  </span>--cephfs-metadata-pool-name<span class=w> </span>default.cephfs.meta<span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-35 name=__codelineno-10-35 href=#__codelineno-10-35></a><span class=w>  </span>--cephfs-data-pool-name<span class=w> </span>default.cephfs.data<span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-36 name=__codelineno-10-36 href=#__codelineno-10-36></a><span class=w>  </span>--rgw-endpoint<span class=w> </span><span class=m>192</span>.168.205.101:8080<span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-37 name=__codelineno-10-37 href=#__codelineno-10-37></a><span class=w>  </span>--rgw-pool-prefix<span class=w> </span>default<span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-38 name=__codelineno-10-38 href=#__codelineno-10-38></a><span class=w>  </span>--format<span class=w> </span>bash
<a id=__codelineno-10-39 name=__codelineno-10-39 href=#__codelineno-10-39></a>
<a id=__codelineno-10-40 name=__codelineno-10-40 href=#__codelineno-10-40></a><span class=c1># Replace following environment</span>
<a id=__codelineno-10-41 name=__codelineno-10-41 href=#__codelineno-10-41></a><span class=nb>export</span><span class=w> </span><span class=nv>ROOK_EXTERNAL_ADMIN_SECRET</span><span class=o>=</span><span class=k>$(</span>sudo<span class=w> </span>ceph<span class=w> </span>auth<span class=w> </span>get-or-create-key<span class=w> </span>client.admin<span class=w> </span>mon<span class=w> </span><span class=s1>&#39;allow *&#39;</span><span class=w> </span>osd<span class=w> </span><span class=s1>&#39;allow *&#39;</span><span class=w> </span>mgr<span class=w> </span><span class=s1>&#39;allow *&#39;</span><span class=w> </span>mds<span class=w> </span><span class=s1>&#39;allow *&#39;</span><span class=k>)</span>
<a id=__codelineno-10-42 name=__codelineno-10-42 href=#__codelineno-10-42></a><span class=nb>export</span><span class=w> </span><span class=nv>ROOK_EXTERNAL_MONITOR_SECRET</span><span class=o>=</span><span class=k>$(</span>sudo<span class=w> </span>ceph<span class=w> </span>auth<span class=w> </span>get-or-create-key<span class=w> </span>mon.<span class=w> </span>mon<span class=w> </span><span class=s1>&#39;allow *&#39;</span><span class=k>)</span>
<a id=__codelineno-10-43 name=__codelineno-10-43 href=#__codelineno-10-43></a>
<a id=__codelineno-10-44 name=__codelineno-10-44 href=#__codelineno-10-44></a>wget<span class=w> </span>https://raw.githubusercontent.com/rook/rook/master/deploy/examples/import-external-cluster.sh
<a id=__codelineno-10-45 name=__codelineno-10-45 href=#__codelineno-10-45></a>chmod<span class=w> </span>+x<span class=w> </span>import-external-cluster.sh
<a id=__codelineno-10-46 name=__codelineno-10-46 href=#__codelineno-10-46></a>./import-external-cluster.sh
<a id=__codelineno-10-47 name=__codelineno-10-47 href=#__codelineno-10-47></a>
<a id=__codelineno-10-48 name=__codelineno-10-48 href=#__codelineno-10-48></a><span class=c1># Delete previous secrets and configmap created</span>
<a id=__codelineno-10-49 name=__codelineno-10-49 href=#__codelineno-10-49></a>kubectl<span class=w> </span>-n<span class=w> </span>rook-ceph<span class=w> </span>delete<span class=w> </span>secret<span class=w> </span>rook-ceph-mon
<a id=__codelineno-10-50 name=__codelineno-10-50 href=#__codelineno-10-50></a>kubectl<span class=w> </span>-n<span class=w> </span>rook-ceph<span class=w> </span>delete<span class=w> </span>cm<span class=w> </span>rook-ceph-mon-endpoints<span class=w> </span>rook-csi-rbd-node<span class=w> </span>csi-rbd-provisioner
<a id=__codelineno-10-51 name=__codelineno-10-51 href=#__codelineno-10-51></a>kubectl<span class=w> </span>delete<span class=w> </span>storageclass<span class=w> </span>ceph-rbd
<a id=__codelineno-10-52 name=__codelineno-10-52 href=#__codelineno-10-52></a>
<a id=__codelineno-10-53 name=__codelineno-10-53 href=#__codelineno-10-53></a><span class=c1>##################################</span>
<a id=__codelineno-10-54 name=__codelineno-10-54 href=#__codelineno-10-54></a><span class=c1># Manually</span>
<a id=__codelineno-10-55 name=__codelineno-10-55 href=#__codelineno-10-55></a><span class=c1>##################################</span>
<a id=__codelineno-10-56 name=__codelineno-10-56 href=#__codelineno-10-56></a>
<a id=__codelineno-10-57 name=__codelineno-10-57 href=#__codelineno-10-57></a><span class=nv>ROOK_ADMIN_KEY</span><span class=o>=</span><span class=k>$(</span>sudo<span class=w> </span>ceph<span class=w> </span>auth<span class=w> </span>get-or-create-key<span class=w> </span>client.admin<span class=w> </span>mon<span class=w> </span><span class=s1>&#39;allow *&#39;</span><span class=w> </span>osd<span class=w> </span><span class=s1>&#39;allow *&#39;</span><span class=w> </span>mgr<span class=w> </span><span class=s1>&#39;allow *&#39;</span><span class=w> </span>mds<span class=w> </span><span class=s1>&#39;allow *&#39;</span><span class=k>)</span>
<a id=__codelineno-10-58 name=__codelineno-10-58 href=#__codelineno-10-58></a><span class=nv>ROOK_MON_KEY</span><span class=o>=</span><span class=k>$(</span>sudo<span class=w> </span>ceph<span class=w> </span>auth<span class=w> </span>get-or-create-key<span class=w> </span>mon.<span class=w> </span>mon<span class=w> </span><span class=s1>&#39;allow *&#39;</span><span class=k>)</span>
<a id=__codelineno-10-59 name=__codelineno-10-59 href=#__codelineno-10-59></a>
<a id=__codelineno-10-60 name=__codelineno-10-60 href=#__codelineno-10-60></a><span class=nb>export</span><span class=w> </span><span class=nv>NAMESPACE</span><span class=o>=</span>rook-ceph
<a id=__codelineno-10-61 name=__codelineno-10-61 href=#__codelineno-10-61></a><span class=nb>export</span><span class=w> </span><span class=nv>ROOK_EXTERNAL_CEPH_MON_DATA</span><span class=o>=</span>server-1<span class=o>=</span><span class=m>192</span>.168.205.101:6789,server-2<span class=o>=</span><span class=m>192</span>.168.205.102:6789,server-3<span class=o>=</span><span class=m>192</span>.168.205.103:6789
<a id=__codelineno-10-62 name=__codelineno-10-62 href=#__codelineno-10-62></a><span class=nb>export</span><span class=w> </span><span class=nv>ROOK_EXTERNAL_FSID</span><span class=o>=</span><span class=k>$(</span>sudo<span class=w> </span>ceph<span class=w> </span>fsid<span class=k>)</span>
<a id=__codelineno-10-63 name=__codelineno-10-63 href=#__codelineno-10-63></a><span class=nb>export</span><span class=w> </span><span class=nv>ROOK_EXTERNAL_CLUSTER_NAME</span><span class=o>=</span><span class=nv>$NAMESPACE</span>
<a id=__codelineno-10-64 name=__codelineno-10-64 href=#__codelineno-10-64></a><span class=nb>export</span><span class=w> </span><span class=nv>ROOK_EXTERNAL_MAX_MON_ID</span><span class=o>=</span><span class=m>0</span>
<a id=__codelineno-10-65 name=__codelineno-10-65 href=#__codelineno-10-65></a>
<a id=__codelineno-10-66 name=__codelineno-10-66 href=#__codelineno-10-66></a>kubectl<span class=w> </span>create<span class=w> </span>namespace<span class=w> </span><span class=nv>$NAMESPACE</span>
<a id=__codelineno-10-67 name=__codelineno-10-67 href=#__codelineno-10-67></a>
<a id=__codelineno-10-68 name=__codelineno-10-68 href=#__codelineno-10-68></a>kubectl<span class=w> </span>-n<span class=w> </span><span class=s2>&quot;</span><span class=nv>$NAMESPACE</span><span class=s2>&quot;</span><span class=w>  </span>create<span class=w> </span>secret<span class=w> </span>generic<span class=w> </span>rook-ceph-mon<span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-69 name=__codelineno-10-69 href=#__codelineno-10-69></a><span class=w> </span>--from-literal<span class=o>=</span>cluster-name<span class=o>=</span><span class=s2>&quot;</span><span class=nv>$ROOK_EXTERNAL_CLUSTER_NAME</span><span class=s2>&quot;</span><span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-70 name=__codelineno-10-70 href=#__codelineno-10-70></a><span class=w> </span>--from-literal<span class=o>=</span><span class=nv>fsid</span><span class=o>=</span><span class=s2>&quot;</span><span class=nv>$ROOK_EXTERNAL_FSID</span><span class=s2>&quot;</span><span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-71 name=__codelineno-10-71 href=#__codelineno-10-71></a><span class=w> </span>--from-literal<span class=o>=</span>admin-secret<span class=o>=</span><span class=s2>&quot;</span><span class=nv>$ROOK_ADMIN_KEY</span><span class=s2>&quot;</span><span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-72 name=__codelineno-10-72 href=#__codelineno-10-72></a><span class=w> </span>--from-literal<span class=o>=</span>mon-secret<span class=o>=</span><span class=s2>&quot;</span><span class=nv>$ROOK_MON_KEY</span><span class=s2>&quot;</span>
<a id=__codelineno-10-73 name=__codelineno-10-73 href=#__codelineno-10-73></a>
<a id=__codelineno-10-74 name=__codelineno-10-74 href=#__codelineno-10-74></a>kubectl<span class=w> </span>-n<span class=w> </span><span class=s2>&quot;</span><span class=nv>$NAMESPACE</span><span class=s2>&quot;</span><span class=w> </span>create<span class=w> </span>configmap<span class=w> </span>rook-ceph-mon-endpoints<span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-75 name=__codelineno-10-75 href=#__codelineno-10-75></a><span class=w> </span>--from-literal<span class=o>=</span><span class=nv>data</span><span class=o>=</span><span class=s2>&quot;</span><span class=nv>$ROOK_EXTERNAL_CEPH_MON_DATA</span><span class=s2>&quot;</span><span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-76 name=__codelineno-10-76 href=#__codelineno-10-76></a><span class=w> </span>--from-literal<span class=o>=</span><span class=nv>mapping</span><span class=o>=</span><span class=s2>&quot;</span><span class=nv>$ROOK_EXTERNAL_MAPPING</span><span class=s2>&quot;</span><span class=w> </span><span class=se>\</span>
<a id=__codelineno-10-77 name=__codelineno-10-77 href=#__codelineno-10-77></a><span class=w> </span>--from-literal<span class=o>=</span><span class=nv>maxMonId</span><span class=o>=</span><span class=s2>&quot;</span><span class=nv>$ROOK_EXTERNAL_MAX_MON_ID</span><span class=s2>&quot;</span>
</code></pre></div> <h2 id=lvm>LVM</h2> <p><strong>Logical Volume Manager</strong> (LVM) plays an important role in the Linux operating system by improving the availability, disk I/O, performance and capability of disk management. LVM is a widely used technique that is extremely flexible for disk management.</p> <p>This adds an extra layer between the <strong>physical disks</strong> and the <strong>file system</strong>, allowing you to create a <strong>logical volume</strong> instead of a physical disk. LVM allows you to easily <code>resize</code>, <code>extend</code> and <code>decrease</code> the logical volume when you need it.</p> <p><a class=glightbox href=images/lvm-diagram.png data-type=image data-width=100% data-height=auto data-desc-position=bottom><img alt=Arch src=images/lvm-diagram.png></a></p> <p>The steps to create logical volumens are the following.</p> <ul> <li>Create a Physical Volumes(PV) on the disk. (<code>pvcreate [Physical Volume Name]</code>)</li> <li>Create the Volume Group(VG) on the Physical Volumes (<code>vgcreate [Volume Group Name] [Physical Volume Name] [Physical Volume Name]</code>)</li> <li>Create Logical Volumes(LV) on the Volume Group (<code>lvcreate L [Logical Volume Size] n [Logical Volume Name] [Name of the Volume Group where the LV to be created]</code>)</li> <li>Create a filesystem for the logical volumes**</li> </ul> <div class=highlight><pre><span></span><code><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=c1># Run all List Blocks devices (look for the TYPE lvm) to identify the correct disk which are to be used in the LVM</span>
<a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a><span class=c1># using the fdisk command or any other disk management command [lsblk].</span>
<a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a>sudo<span class=w> </span>lsblk<span class=w> </span><span class=c1># sudo fdisk -l</span>
<a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a>
<a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a><span class=c1># NAME                      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS</span>
<a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a><span class=c1># loop0                       7:0    0 69.2M  1 loop /snap/core22/1125</span>
<a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a><span class=c1># loop2                       7:2    0 35.2M  1 loop /snap/snapd/20674</span>
<a id=__codelineno-11-8 name=__codelineno-11-8 href=#__codelineno-11-8></a><span class=c1># vda                       252:0    0   60G  0 disk</span>
<a id=__codelineno-11-9 name=__codelineno-11-9 href=#__codelineno-11-9></a><span class=c1># vda1                    252:1    0    1G  0 part /boot/efi</span>
<a id=__codelineno-11-10 name=__codelineno-11-10 href=#__codelineno-11-10></a><span class=c1># vda2                    252:2    0    2G  0 part /boot</span>
<a id=__codelineno-11-11 name=__codelineno-11-11 href=#__codelineno-11-11></a><span class=c1># vda3                    252:3    0 56.9G  0 part</span>
<a id=__codelineno-11-12 name=__codelineno-11-12 href=#__codelineno-11-12></a><span class=c1>#   ubuntu--vg-ubuntu--lv 253:0    0 28.5G  0 lvm  /</span>
<a id=__codelineno-11-13 name=__codelineno-11-13 href=#__codelineno-11-13></a>
<a id=__codelineno-11-14 name=__codelineno-11-14 href=#__codelineno-11-14></a><span class=c1># The pvdisplay command provides a verbose multi-line output for each physical volume. It displays physical properties (size, extents, volume group, etc.) in a fixed format.</span>
<a id=__codelineno-11-15 name=__codelineno-11-15 href=#__codelineno-11-15></a>sudo<span class=w> </span>pvdisplay
<a id=__codelineno-11-16 name=__codelineno-11-16 href=#__codelineno-11-16></a>
<a id=__codelineno-11-17 name=__codelineno-11-17 href=#__codelineno-11-17></a><span class=c1># The pvscan command scans all supported LVM block devices in the system for physical volumes.</span>
<a id=__codelineno-11-18 name=__codelineno-11-18 href=#__codelineno-11-18></a>sudo<span class=w> </span>pvscan
<a id=__codelineno-11-19 name=__codelineno-11-19 href=#__codelineno-11-19></a>
<a id=__codelineno-11-20 name=__codelineno-11-20 href=#__codelineno-11-20></a><span class=c1>#  PV /dev/vda3   VG ubuntu-vg       lvm2 [&lt;56.95 GiB / 28.47 GiB free]</span>
<a id=__codelineno-11-21 name=__codelineno-11-21 href=#__codelineno-11-21></a><span class=c1>#  Total: 1 [&lt;56.95 GiB] / in use: 1 [&lt;56.95 GiB] / in no VG: 0 [0   ]</span>
<a id=__codelineno-11-22 name=__codelineno-11-22 href=#__codelineno-11-22></a>
<a id=__codelineno-11-23 name=__codelineno-11-23 href=#__codelineno-11-23></a><span class=c1>#  --- Physical volume ---</span>
<a id=__codelineno-11-24 name=__codelineno-11-24 href=#__codelineno-11-24></a><span class=c1>#  PV Name               /dev/vda3</span>
<a id=__codelineno-11-25 name=__codelineno-11-25 href=#__codelineno-11-25></a><span class=c1>#  VG Name               ubuntu-vg</span>
<a id=__codelineno-11-26 name=__codelineno-11-26 href=#__codelineno-11-26></a><span class=c1>#  PV Size               &lt;56.95 GiB / not usable 3.00 MiB</span>
<a id=__codelineno-11-27 name=__codelineno-11-27 href=#__codelineno-11-27></a><span class=c1>#  Allocatable           yes</span>
<a id=__codelineno-11-28 name=__codelineno-11-28 href=#__codelineno-11-28></a><span class=c1>#  PE Size               4.00 MiB</span>
<a id=__codelineno-11-29 name=__codelineno-11-29 href=#__codelineno-11-29></a><span class=c1>#  Total PE              14578</span>
<a id=__codelineno-11-30 name=__codelineno-11-30 href=#__codelineno-11-30></a><span class=c1>#  Free PE               7289</span>
<a id=__codelineno-11-31 name=__codelineno-11-31 href=#__codelineno-11-31></a><span class=c1>#  Allocated PE          7289</span>
<a id=__codelineno-11-32 name=__codelineno-11-32 href=#__codelineno-11-32></a><span class=c1>#  PV UUID               9ZIc1w-wRGn-7LbN-Xnmk-czBV-QcX9-5XGnR2</span>
<a id=__codelineno-11-33 name=__codelineno-11-33 href=#__codelineno-11-33></a>
<a id=__codelineno-11-34 name=__codelineno-11-34 href=#__codelineno-11-34></a><span class=c1>#Get the volumes groups already creted</span>
<a id=__codelineno-11-35 name=__codelineno-11-35 href=#__codelineno-11-35></a>sudo<span class=w> </span>vgs
<a id=__codelineno-11-36 name=__codelineno-11-36 href=#__codelineno-11-36></a>
<a id=__codelineno-11-37 name=__codelineno-11-37 href=#__codelineno-11-37></a><span class=c1>#  VG        #PV #LV #SN Attr   VSize   VFree</span>
<a id=__codelineno-11-38 name=__codelineno-11-38 href=#__codelineno-11-38></a><span class=c1>#  ubuntu-vg   1   1   0 wz--n- &lt;56.95g 28.47g</span>
<a id=__codelineno-11-39 name=__codelineno-11-39 href=#__codelineno-11-39></a>
<a id=__codelineno-11-40 name=__codelineno-11-40 href=#__codelineno-11-40></a><span class=c1># Create Logical Volume</span>
<a id=__codelineno-11-41 name=__codelineno-11-41 href=#__codelineno-11-41></a>sudo<span class=w> </span>lvcreate<span class=w> </span>-L<span class=w> </span>4GB<span class=w> </span>-n<span class=w> </span>lv1<span class=w> </span>ubuntu-vg
<a id=__codelineno-11-42 name=__codelineno-11-42 href=#__codelineno-11-42></a>
<a id=__codelineno-11-43 name=__codelineno-11-43 href=#__codelineno-11-43></a><span class=c1># List Logical Volumes</span>
<a id=__codelineno-11-44 name=__codelineno-11-44 href=#__codelineno-11-44></a>sudo<span class=w> </span>lvs
<a id=__codelineno-11-45 name=__codelineno-11-45 href=#__codelineno-11-45></a>
<a id=__codelineno-11-46 name=__codelineno-11-46 href=#__codelineno-11-46></a><span class=c1># Format the logical volumen with ext4 format (sudo lsblk -f)</span>
<a id=__codelineno-11-47 name=__codelineno-11-47 href=#__codelineno-11-47></a>sudo<span class=w> </span>mkfs<span class=w> </span>-t<span class=w> </span>ext4<span class=w> </span>/dev/ubuntu-vg/lv1
<a id=__codelineno-11-48 name=__codelineno-11-48 href=#__codelineno-11-48></a>
<a id=__codelineno-11-49 name=__codelineno-11-49 href=#__codelineno-11-49></a><span class=c1>#Create filesystem for the logical volumes and mount into the mapper</span>
<a id=__codelineno-11-50 name=__codelineno-11-50 href=#__codelineno-11-50></a><span class=c1># The device mapper is a framework provided by the Linux kernel for mapping physical block devices onto higher-level virtual block devices. It forms the foundation of the logical volume manager (LVM), software RAIDs and dm-crypt disk encryption, and offers additional features such as file system snapshots.</span>
<a id=__codelineno-11-51 name=__codelineno-11-51 href=#__codelineno-11-51></a>sudo<span class=w> </span>mkdir<span class=w> </span>-p<span class=w> </span>/data/01
<a id=__codelineno-11-52 name=__codelineno-11-52 href=#__codelineno-11-52></a>sudo<span class=w> </span>mount<span class=w> </span>/dev/mapper/ubuntu--vg-lv1<span class=w> </span>/data/01
<a id=__codelineno-11-53 name=__codelineno-11-53 href=#__codelineno-11-53></a>
<a id=__codelineno-11-54 name=__codelineno-11-54 href=#__codelineno-11-54></a><span class=c1># To mount it permanently use that UUID number and paste it inside etc/fstab path</span>
<a id=__codelineno-11-55 name=__codelineno-11-55 href=#__codelineno-11-55></a><span class=c1>#   https://xan.manning.io/2017/05/29/best-practice-for-mounting-an-lvm-logical-volume-with-etc-fstab.html</span>
<a id=__codelineno-11-56 name=__codelineno-11-56 href=#__codelineno-11-56></a><span class=c1>#  sudo apt install vim -y</span>
<a id=__codelineno-11-57 name=__codelineno-11-57 href=#__codelineno-11-57></a>sudo<span class=w> </span>blkid<span class=w> </span><span class=p>|</span><span class=w> </span>grep<span class=w> </span>ubuntu--vg-lv1
<a id=__codelineno-11-58 name=__codelineno-11-58 href=#__codelineno-11-58></a>
<a id=__codelineno-11-59 name=__codelineno-11-59 href=#__codelineno-11-59></a><span class=c1># /dev/mapper/ubuntu--vg-ubuntu--lv: UUID=&quot;b3087c64-de0a-41f0-b77f-85b67b8d9b26&quot; BLOCK_SIZE=&quot;4096&quot; TYPE=&quot;ext4&quot;</span>
<a id=__codelineno-11-60 name=__codelineno-11-60 href=#__codelineno-11-60></a><span class=c1># /dev/mapper/ubuntu--vg-mylv: UUID=&quot;ca9f7725-5a84-4757-b112-158598bc7a5c&quot; BLOCK_SIZE=&quot;4096&quot; TYPE=&quot;ext4&quot;</span>
<a id=__codelineno-11-61 name=__codelineno-11-61 href=#__codelineno-11-61></a>sudo<span class=w> </span>vi<span class=w> </span>/etc/fstab
<a id=__codelineno-11-62 name=__codelineno-11-62 href=#__codelineno-11-62></a>
<a id=__codelineno-11-63 name=__codelineno-11-63 href=#__codelineno-11-63></a><span class=c1># Add following line</span>
<a id=__codelineno-11-64 name=__codelineno-11-64 href=#__codelineno-11-64></a>/dev/mapper/ubuntu--vg-lv1<span class=w> </span>/data/01<span class=w>  </span>ext4<span class=w> </span>defaults<span class=w> </span><span class=m>0</span><span class=w> </span><span class=m>2</span>
<a id=__codelineno-11-65 name=__codelineno-11-65 href=#__codelineno-11-65></a>
<a id=__codelineno-11-66 name=__codelineno-11-66 href=#__codelineno-11-66></a><span class=c1># Finally get all the mounted locations</span>
<a id=__codelineno-11-67 name=__codelineno-11-67 href=#__codelineno-11-67></a><span class=c1># https://github.com/rook/rook/blob/master/design/ceph/ceph-volume-provisioning.md</span>
<a id=__codelineno-11-68 name=__codelineno-11-68 href=#__codelineno-11-68></a>sudo<span class=w> </span>df<span class=w> </span>-h
<a id=__codelineno-11-69 name=__codelineno-11-69 href=#__codelineno-11-69></a>sudo<span class=w> </span>lsblk
<a id=__codelineno-11-70 name=__codelineno-11-70 href=#__codelineno-11-70></a>
<a id=__codelineno-11-71 name=__codelineno-11-71 href=#__codelineno-11-71></a>sudo<span class=w> </span>reboot
</code></pre></div> <h3 id=lvm-rook-ceph>LVM Rook-Ceph</h3> <p>Using Rook Ceph, the logical volume must be created and formatted. So, as if the physical disks is not empty, it would be neecesary to formtat the device.</p> <div class=highlight><pre><span></span><code><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=c1># Create Logical Volume</span>
<a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a>sudo<span class=w> </span>lvcreate<span class=w> </span>-L<span class=w> </span>4GB<span class=w> </span>-n<span class=w> </span>lv1<span class=w> </span>ubuntu-vg
<a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>
<a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a><span class=nv>DISK</span><span class=o>=</span><span class=s2>&quot;/dev/mapper/ubuntu--vg-lv1&quot;</span>
<a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a>sudo<span class=w> </span>dd<span class=w> </span><span class=k>if</span><span class=o>=</span>/dev/zero<span class=w> </span><span class=nv>of</span><span class=o>=</span><span class=s2>&quot;</span><span class=nv>$DISK</span><span class=s2>&quot;</span><span class=w> </span><span class=nv>bs</span><span class=o>=</span>1M<span class=w> </span><span class=nv>count</span><span class=o>=</span><span class=m>100</span><span class=w> </span><span class=nv>oflag</span><span class=o>=</span>direct,dsync
<a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a>sudo<span class=w> </span>sgdisk<span class=w> </span>--zap-all<span class=w> </span><span class=nv>$DISK</span>
<a id=__codelineno-12-7 name=__codelineno-12-7 href=#__codelineno-12-7></a>
<a id=__codelineno-12-8 name=__codelineno-12-8 href=#__codelineno-12-8></a>
<a id=__codelineno-12-9 name=__codelineno-12-9 href=#__codelineno-12-9></a><span class=c1># Remove Logical Volume</span>
<a id=__codelineno-12-10 name=__codelineno-12-10 href=#__codelineno-12-10></a>sudo<span class=w> </span>lvremove<span class=w> </span>/dev/ubuntu-vg/lv1
<a id=__codelineno-12-11 name=__codelineno-12-11 href=#__codelineno-12-11></a>
<a id=__codelineno-12-12 name=__codelineno-12-12 href=#__codelineno-12-12></a><span class=c1># Check current device</span>
<a id=__codelineno-12-13 name=__codelineno-12-13 href=#__codelineno-12-13></a>sudo<span class=w> </span>lsblk<span class=w> </span>/dev/dm-1<span class=w> </span>--bytes<span class=w> </span>--nodeps<span class=w> </span>--pairs<span class=w> </span>--paths<span class=w> </span>--output<span class=w> </span>SIZE,ROTA,RO,TYPE,PKNAME,NAME,KNAME,MOUNTPOINT,FSTYPE
<a id=__codelineno-12-14 name=__codelineno-12-14 href=#__codelineno-12-14></a>sudo<span class=w> </span>lsblk<span class=w> </span>/dev/mapper/ubuntu--vg-lv1<span class=w> </span>--bytes<span class=w> </span>--nodeps<span class=w> </span>--pairs<span class=w> </span>--paths<span class=w> </span>--output<span class=w> </span>SIZE,ROTA,RO,TYPE,PKNAME,NAME,KNAME,MOUNTPOINT,FSTYPE
<a id=__codelineno-12-15 name=__codelineno-12-15 href=#__codelineno-12-15></a>
<a id=__codelineno-12-16 name=__codelineno-12-16 href=#__codelineno-12-16></a><span class=c1>#SIZE=&quot;4294967296&quot; ROTA=&quot;1&quot; RO=&quot;0&quot; TYPE=&quot;lvm&quot; PKNAME=&quot;&quot; NAME=&quot;/dev/mapper/ubuntu--vg-lv1&quot; KNAME=&quot;/dev/dm-1&quot; MOUNTPOINT=&quot;&quot; FSTYPE=&quot;&quot;</span>
</code></pre></div> <h2 id=references>References</h2> <ul> <li>[https://www.youtube.com/watch?v=Uvbp3mtOltw]</li> <li>[https://www.youtube.com/watch?v=98QujsS7jFI&amp;t=1630s]</li> <li>[https://www.youtube.com/watch?v=cR-s26Zzx4Y]</li> </ul> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">February 13, 2025</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> &copy; 2024 <a href=https://github.com/jsa4000 target=_blank rel=noopener>Javier Santos</a> </div> </div> <div class=md-social> <a href=https://github.com/jsa4000 target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 480 512"><!-- Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg> </a> <a href=https://github.com/jsa4000 target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> </a> <a href=https://www.linkedin.com/in/javier-santos-andres/ target=_blank rel=noopener title=www.linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["header.autohide", "navigation.tabs", "navigation.top", "navigation.instant", "navigation.tracking", "toc.integrate", "search.suggest", "search.share", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.annotate", "content.code.copy"], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../assets/javascripts/bundle.c8d2eff1.min.js></script> <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>